{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow linear model tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using tf.learn api to solve a binary classification problem<br>\n",
    "given census data on age, gender, education, occupation-->predict whether or not the person earns more tha 50,000dollars or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the Cencus Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import urllib\n",
    "import pandas as pd\n",
    "# import tempfile\n",
    "# import urllib.request\n",
    "# train_file=urllib.request.urlretrieve(\"http://mlr.cs.umass.edu/ml/machine-learning-databases/adult/adult.data\")\n",
    "# test_file=urllib.request.urlretrieve(\"http://mlr.cs.umass.edu/ml/machine-learning-databases/adult/adult.test\")\n",
    "\n",
    "df_train=pd.read_csv('train.csv')\n",
    "\n",
    "df_test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLUMNS = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
    "           \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\",\n",
    "           \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\",\n",
    "           \"income_bracket\"]\n",
    "df_train=pd.read_csv('train.csv', names=COLUMNS,skipinitialspace=True)\n",
    "df_test=pd.read_csv('test.csv', names=COLUMNS,skipinitialspace=True,skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16281, 15)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABEL_COLUMN = \"label\"\n",
    "df_train[LABEL_COLUMN] = (df_train[\"income_bracket\"].apply(lambda x: \">50K\" in x)).astype(int)\n",
    "df_test[LABEL_COLUMN] = (df_test[\"income_bracket\"].apply(lambda x: \">50K\" in x)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = [\"workclass\", \"education\", \"marital_status\", \"occupation\",\n",
    "                       \"relationship\", \"race\", \"gender\", \"native_country\"]\n",
    "CONTINUOUS_COLUMNS = [\"age\", \"education_num\", \"capital_gain\", \"capital_loss\", \"hours_per_week\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting Data into Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def input_fn(df):\n",
    "  # Creates a dictionary mapping from each continuous feature column name (k) to\n",
    "  # the values of that column stored in a constant Tensor.\n",
    "  continuous_cols = {k: tf.constant(df[k].values)\n",
    "                     for k in CONTINUOUS_COLUMNS}\n",
    "  # Creates a dictionary mapping from each categorical feature column name (k)\n",
    "  # to the values of that column stored in a tf.SparseTensor.\n",
    "  categorical_cols = {k: tf.SparseTensor(\n",
    "      indices=[[i, 0] for i in range(df[k].size)],\n",
    "      values=df[k].values,\n",
    "      dense_shape=[df[k].size, 1])\n",
    "                      for k in CATEGORICAL_COLUMNS}\n",
    "  # Merges the two dictionaries into one.\n",
    "  #feature_cols = dict(continuous_cols.items() + categorical_cols.items())\n",
    "  feature_cols= continuous_cols.copy()\n",
    "  feature_cols.update(categorical_cols)\n",
    "  # Converts the label column into a constant Tensor.\n",
    "  label = tf.constant(df[LABEL_COLUMN].values)\n",
    "  # Returns the feature columns and the label.\n",
    "  return feature_cols, label\n",
    "\n",
    "def train_input_fn():\n",
    "  return input_fn(df_train)\n",
    "\n",
    "def eval_input_fn():\n",
    "  return input_fn(df_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting and Enginerring Features for the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting and crafting the right set of feature columns is key to learning an effective model. A feature column can be either one of the raw columns in the original dataframe (let's call them base feature columns), or any new columns created based on some transformations defined over one or multiple base columns (let's call them derived feature columns). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Base Categorical Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gender = tf.contrib.layers.sparse_column_with_keys(\n",
    "  column_name=\"gender\", keys=[\"Female\", \"Male\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "education = tf.contrib.layers.sparse_column_with_hash_bucket(\"education\", hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What will happen is that each possible value in the feature column education will be hashed to an integer ID as we encounter them in training. See an example illustration below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "race = tf.contrib.layers.sparse_column_with_hash_bucket(\"race\", hash_bucket_size=100)\n",
    "marital_status = tf.contrib.layers.sparse_column_with_hash_bucket(\"marital_status\", hash_bucket_size=100)\n",
    "relationship = tf.contrib.layers.sparse_column_with_hash_bucket(\"relationship\", hash_bucket_size=100)\n",
    "workclass = tf.contrib.layers.sparse_column_with_hash_bucket(\"workclass\", hash_bucket_size=100)\n",
    "occupation = tf.contrib.layers.sparse_column_with_hash_bucket(\"occupation\", hash_bucket_size=1000)\n",
    "native_country = tf.contrib.layers.sparse_column_with_hash_bucket(\"native_country\", hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Base Continuous Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age = tf.contrib.layers.real_valued_column(\"age\")\n",
    "education_num = tf.contrib.layers.real_valued_column(\"education_num\")\n",
    "capital_gain = tf.contrib.layers.real_valued_column(\"capital_gain\")\n",
    "capital_loss = tf.contrib.layers.real_valued_column(\"capital_loss\")\n",
    "hours_per_week = tf.contrib.layers.real_valued_column(\"hours_per_week\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Making Continuous Features Categorical thru Bucketization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Bucketization is a process of dividing the entire range of a continuous feature into a set of consecutive bins/buckets, and then converting the original numerical feature into a bucket ID (as a categorical feature) depending on which bucket that value falls into. So, we can define a bucketized_column over age as:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_buckets = tf.contrib.layers.bucketized_column(age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "education_x_occupation = tf.contrib.layers.crossed_column([education, occupation], hash_bucket_size=int(1e4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "독립변수들 간의 교호작용을 고려"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_buckets_x_education_x_occupation = tf.contrib.layers.crossed_column(\n",
    "  [age_buckets, education, occupation], hash_bucket_size=int(1e6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining The Logistic Regression Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지<br>\n",
    "# processing the input data \n",
    "# defining all the feature columns\n",
    "# --> now ready to put them all together and build a Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_num_ps_replicas': 0, '_environment': 'local', '_tf_random_seed': None, '_num_worker_replicas': 0, '_is_chief': True, '_session_config': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_task_id': 0, '_task_type': None, '_save_summary_steps': 100, '_keep_checkpoint_max': 5, '_model_dir': 'C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Temp\\\\tmprkyaximp', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000025E3A43ADA0>}\n"
     ]
    }
   ],
   "source": [
    "model_dir = tempfile.mkdtemp()\n",
    "m = tf.contrib.learn.LinearClassifier(feature_columns=[\n",
    "  gender, native_country, education, occupation, workclass, marital_status, race,\n",
    "  age_buckets, education_x_occupation, age_buckets_x_education_x_occupation],\n",
    "  model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluating Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\feature_column.py:2306: calling sparse_feature_cross (from tensorflow.contrib.layers.python.ops.sparse_feature_cross_op) with hash_key=None is deprecated and will be removed after 2016-11-20.\n",
      "Instructions for updating:\n",
      "The default behavior of sparse_feature_cross is changing, the default\n",
      "value for hash_key will change to SPARSE_FEATURE_CROSS_DEFAULT_HASH_KEY.\n",
      "From that point on sparse_feature_cross will always use FingerprintCat64\n",
      "to concatenate the feature fingerprints. And the underlying\n",
      "_sparse_feature_cross_op.sparse_feature_cross operation will be marked\n",
      "as deprecated.\n",
      "WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\feature_column.py:2306: calling sparse_feature_cross (from tensorflow.contrib.layers.python.ops.sparse_feature_cross_op) with hash_key=None is deprecated and will be removed after 2016-11-20.\n",
      "Instructions for updating:\n",
      "The default behavior of sparse_feature_cross is changing, the default\n",
      "value for hash_key will change to SPARSE_FEATURE_CROSS_DEFAULT_HASH_KEY.\n",
      "From that point on sparse_feature_cross will always use FingerprintCat64\n",
      "to concatenate the feature fingerprints. And the underlying\n",
      "_sparse_feature_cross_op.sparse_feature_cross operation will be marked\n",
      "as deprecated.\n",
      "WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'int32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int32'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\User\\AppData\\Local\\Temp\\tmprkyaximp\\model.ckpt-1000\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into C:\\Users\\User\\AppData\\Local\\Temp\\tmprkyaximp\\model.ckpt.\n",
      "INFO:tensorflow:step = 1001, loss = 0.372576\n",
      "INFO:tensorflow:global_step/sec: 28.6386\n",
      "INFO:tensorflow:step = 1101, loss = 0.368592 (3.492 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1200 into C:\\Users\\User\\AppData\\Local\\Temp\\tmprkyaximp\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.365802.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearClassifier(params={'optimizer': <tensorflow.python.training.ftrl.FtrlOptimizer object at 0x0000025E42F49AC8>, 'joint_weights': False, 'head': <tensorflow.contrib.learn.python.learn.estimators.head._BinaryLogisticHead object at 0x0000025F6DC9F978>, 'feature_columns': [_SparseColumnKeys(column_name='gender', is_integerized=False, bucket_size=None, lookup_config=_SparseIdLookupConfig(vocabulary_file=None, keys=('Female', 'Male'), num_oov_buckets=0, vocab_size=2, default_value=-1), combiner='sum', dtype=tf.string), _SparseColumnHashed(column_name='native_country', is_integerized=False, bucket_size=1000, lookup_config=None, combiner='sum', dtype=tf.string), _SparseColumnHashed(column_name='education', is_integerized=False, bucket_size=1000, lookup_config=None, combiner='sum', dtype=tf.string), _SparseColumnHashed(column_name='occupation', is_integerized=False, bucket_size=1000, lookup_config=None, combiner='sum', dtype=tf.string), _SparseColumnHashed(column_name='workclass', is_integerized=False, bucket_size=100, lookup_config=None, combiner='sum', dtype=tf.string), _SparseColumnHashed(column_name='marital_status', is_integerized=False, bucket_size=100, lookup_config=None, combiner='sum', dtype=tf.string), _SparseColumnHashed(column_name='race', is_integerized=False, bucket_size=100, lookup_config=None, combiner='sum', dtype=tf.string), _BucketizedColumn(source_column=_RealValuedColumn(column_name='age', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)), _CrossedColumn(columns=(_SparseColumnHashed(column_name='education', is_integerized=False, bucket_size=1000, lookup_config=None, combiner='sum', dtype=tf.string), _SparseColumnHashed(column_name='occupation', is_integerized=False, bucket_size=1000, lookup_config=None, combiner='sum', dtype=tf.string)), hash_bucket_size=10000, hash_key=None, combiner='sum', ckpt_to_load_from=None, tensor_name_in_ckpt=None), _CrossedColumn(columns=(_BucketizedColumn(source_column=_RealValuedColumn(column_name='age', dimension=1, default_value=None, dtype=tf.float32, normalizer=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)), _SparseColumnHashed(column_name='education', is_integerized=False, bucket_size=1000, lookup_config=None, combiner='sum', dtype=tf.string), _SparseColumnHashed(column_name='occupation', is_integerized=False, bucket_size=1000, lookup_config=None, combiner='sum', dtype=tf.string)), hash_bucket_size=1000000, hash_key=None, combiner='sum', ckpt_to_load_from=None, tensor_name_in_ckpt=None)], 'gradient_clip_norm': None})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(input_fn=train_input_fn, steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\feature_column.py:2306: calling sparse_feature_cross (from tensorflow.contrib.layers.python.ops.sparse_feature_cross_op) with hash_key=None is deprecated and will be removed after 2016-11-20.\n",
      "Instructions for updating:\n",
      "The default behavior of sparse_feature_cross is changing, the default\n",
      "value for hash_key will change to SPARSE_FEATURE_CROSS_DEFAULT_HASH_KEY.\n",
      "From that point on sparse_feature_cross will always use FingerprintCat64\n",
      "to concatenate the feature fingerprints. And the underlying\n",
      "_sparse_feature_cross_op.sparse_feature_cross operation will be marked\n",
      "as deprecated.\n",
      "WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\feature_column.py:2306: calling sparse_feature_cross (from tensorflow.contrib.layers.python.ops.sparse_feature_cross_op) with hash_key=None is deprecated and will be removed after 2016-11-20.\n",
      "Instructions for updating:\n",
      "The default behavior of sparse_feature_cross is changing, the default\n",
      "value for hash_key will change to SPARSE_FEATURE_CROSS_DEFAULT_HASH_KEY.\n",
      "From that point on sparse_feature_cross will always use FingerprintCat64\n",
      "to concatenate the feature fingerprints. And the underlying\n",
      "_sparse_feature_cross_op.sparse_feature_cross operation will be marked\n",
      "as deprecated.\n",
      "WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:625: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'int32'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int32'> labels to bool.\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-17-14:05:24\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\User\\AppData\\Local\\Temp\\tmprkyaximp\\model.ckpt-1200\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-17-14:05:25\n",
      "INFO:tensorflow:Saving dict for global step 1200: accuracy = 0.833425, accuracy/baseline_label_mean = 0.236226, accuracy/threshold_0.500000_mean = 0.833425, auc = 0.877255, auc_precision_recall = 0.681047, global_step = 1200, labels/actual_label_mean = 0.236226, labels/prediction_mean = 0.24185, loss = 0.361486, precision/positive_threshold_0.500000_mean = 0.711567, recall/positive_threshold_0.500000_mean = 0.49584\n",
      "accuracy: 0.833425\n",
      "accuracy/baseline_label_mean: 0.236226\n",
      "accuracy/threshold_0.500000_mean: 0.833425\n",
      "auc: 0.877255\n",
      "auc_precision_recall: 0.681047\n",
      "global_step: 1200\n",
      "labels/actual_label_mean: 0.236226\n",
      "labels/prediction_mean: 0.24185\n",
      "loss: 0.361486\n",
      "precision/positive_threshold_0.500000_mean: 0.711567\n",
      "recall/positive_threshold_0.500000_mean: 0.49584\n"
     ]
    }
   ],
   "source": [
    "results = m.evaluate(input_fn=eval_input_fn, steps=1)\n",
    "for key in sorted(results):\n",
    "    print(\"%s: %s\" % (key, results[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Regularization to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_num_ps_replicas': 0, '_environment': 'local', '_tf_random_seed': None, '_num_worker_replicas': 0, '_is_chief': True, '_session_config': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_task_id': 0, '_task_type': None, '_save_summary_steps': 100, '_keep_checkpoint_max': 5, '_model_dir': 'C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Temp\\\\tmprkyaximp', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000025F6DC9F518>}\n"
     ]
    }
   ],
   "source": [
    "m = tf.contrib.learn.LinearClassifier(feature_columns=[\n",
    "  gender, native_country, education, occupation, workclass, marital_status, race,\n",
    "  age_buckets, education_x_occupation, age_buckets_x_education_x_occupation],\n",
    "  optimizer=tf.train.FtrlOptimizer(\n",
    "    learning_rate=0.1,\n",
    "    l1_regularization_strength=1.0,\n",
    "    l2_regularization_strength=1.0),\n",
    "  model_dir=model_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
